@conflict llama-cpp-*
%%vulkan%%
include/ggml-alloc.h
include/ggml-backend.h
include/ggml-blas.h
include/ggml-cann.h
include/ggml-cpp.h
include/ggml-cpu.h
include/ggml-cuda.h
include/ggml-metal.h
include/ggml-opt.h
include/ggml-rpc.h
include/ggml-sycl.h
include/ggml-vulkan.h
include/ggml-webgpu.h
include/ggml-zendnn.h
include/ggml.h
include/gguf.h
lib/cmake/ggml/
lib/cmake/ggml/ggml-config.cmake
lib/cmake/ggml/ggml-version.cmake
@lib lib/libggml-base.so.${LIBggml-base_VERSION}
%%cpu%%
%%amd64%%
@lib lib/libggml.so.${LIBggml_VERSION}
share/pkgconfig/ggml.pc
